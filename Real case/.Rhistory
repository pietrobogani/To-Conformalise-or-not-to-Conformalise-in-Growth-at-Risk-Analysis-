sum(x1[1,] * coef(QR))
coef(QR)
Time[jt]
apply(Z, 2, function(x) var(x) > 1e-5)
Z$ABSI
View(Z)
#This script....
# NOTE: this script should be run separately for one quarter and four quarter ahead forecast horizons
# by manually changing the variable 'h'.
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)
# Clear workspace
rm(list = ls())
# Set forecast horizon
h <- 4
loadsavedresults = FALSE; # TRUE If I have run the code already and I want to load results, stored in ResOOS_CQR_QR_H
# Load data and functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/To-Conformalise-or-not-to-Conformalise-in-Growth-at-Risk-Analysis/functions.R")
file_path <- "Data_NFCI_div.xls"
# Read the file and  Filter data for 1973Q1-2015Q4
data <- read_excel(file_path)
data <- data[,-c(3:10)] # Making sure to have only components of NFCI i
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time
# Set forecast settings
QQ <- seq(0.03, 0.99, by = 0.01) #We don't implement a smoothing, as in Adrian et al., but use a much finer quantile grid
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)
Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
Yh[1:(h-1)] <- NA
}
#This script....
# NOTE: this script should be run separately for one quarter and four quarter ahead forecast horizons
# by manually changing the variable 'h'.
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)
# Clear workspace
rm(list = ls())
# Set forecast horizon
h <- 4
loadsavedresults = FALSE; # TRUE If I have run the code already and I want to load results, stored in ResOOS_CQR_QR_H
# Load data and functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/To-Conformalise-or-not-to-Conformalise-in-Growth-at-Risk-Analysis/functions.R")
file_path <- "Data_NFCI_div.xls"
# Read the file and  Filter data for 1973Q1-2015Q4
data <- read_excel(file_path)
data <- data[,-c(3:10)] # Making sure to have only components of NFCI i
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time
# Set forecast settings
QQ <- seq(0.03, 0.99, by = 0.01) #We don't implement a smoothing, as in Adrian et al., but use a much finer quantile grid
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)
Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
Yh[1:(h-1)] <- NA
}
View(X)
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)
# Clear workspace
rm(list = ls())
# Set forecast horizon
h <- 4
loadsavedresults = FALSE; # TRUE If I have run the code already and I want to load results, stored in ResOOS_CQR_QR_H
# Load data and functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/To-Conformalise-or-not-to-Conformalise-in-Growth-at-Risk-Analysis/functions.R")
file_path <- "Data_NFCI_div.xls"
# Read the file and  Filter data for 1973Q1-2015Q4
data <- read_excel(file_path)
data <- data[,-c(3:10)] # Making sure to have only components of NFCI i
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time
# Set forecast settings
QQ <- seq(0.03, 0.99, by = 0.01) #We don't implement a smoothing, as in Adrian et al., but use a much finer quantile grid
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)
Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
Yh[1:(h-1)] <- NA
}
# Construct matrices of regressors
Z <- as.matrix(cbind(1, scale(X[,-1]), y))
ZGDPonly <- cbind(1, y)
if (loadsavedresults == FALSE) {
{
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)
# Raw quantiles
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_low_OOSCOdiv <- YQ_NaNs
YQ_high_OOSCOdiv <- YQ_NaNs
YQ_OOSCOdiv <- YQ_NaNs
YQGDPonly_high_OOSCOdiv <- YQ_NaNs
YQGDPonly_low_OOSCOdiv <- YQ_NaNs
YQGDPonly_OOSCOdiv <- YQ_NaNs
# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_OOSCOdiv <- Pit_NaNs
PitSTGDPonly_OOSCOdiv <- Pit_NaNs
}
for (jt in jtFirstOOS:(length(Time) - h)) {
YhRealized <- Yh[jt + h]
if (lubridate::month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
#------- CQR QR with NFCI components and GDP, out-of-sample
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
Z_temp <- Z
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length+1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
x0 <- Z[1:test_length,]
x1 <- Z[(test_length+1):(jt - h),]
# ---- Preparation for PCA
# I save them now, I will add them back at the end of PCA
x0_y <- x0[,"y"]
x1_y <- x1[,"y"]
Z_y <- Z_temp[,"y"]
# I remove the column of 1 and "y", the past GDP observation
x0 <- x0[, - ncol(x0)]
x1 <- x1[, - ncol(x1)]
Z_temp <- Z_temp[,- ncol(Z_temp)]
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-5)
x0 <- x0[, indexes]
x1 <- x1[, indexes]
Z_temp <- Z_temp[, indexes]
x0 <- as.matrix(cbind(cbind(x0),x0_y))
x1 <- as.matrix(cbind(cbind(x1),x1_y))
Z_temp <- as.matrix(cbind(cbind(Z_temp),Z_y))
# pca_result <- prcomp(x0, center = TRUE, scale. = TRUE)
# cumulative_variance <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
# num_components <- which(cumulative_variance >= 0.90)[1] # Capture 90% of total variance
# selected_components <- pca_result$x[, 1:num_components]
#
# x1_projected <- predict(pca_result, newdata = x1)[, 1:num_components]
# Z_temp_projected <- predict(pca_result, newdata = Z_temp)[, 1:num_components]
#
# x0 <- as.matrix(cbind(cbind(selected_components),x0_y))
# x1 <- as.matrix(cbind(cbind(x1_projected),x1_y))
# Z_temp <- as.matrix(cbind(cbind(Z_temp_projected),Z_y))
x_test <- t(as.matrix(Z_temp[jt,]))
YQ_OOSCOdiv[jt + h, ] <- qCQR_opposite(x0,y0,x1,y1,x_test,QQ)
YQGDPonly_OOSCOdiv[jt + h, ] <- qCQR_opposite(xGDPonly0,y0,xGDPonly1,y1,xGDPonly_test,QQ)
PitST_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQ_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
PitSTGDPonly_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
}
}
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
Z_temp <- Z
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length+1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
x0 <- Z[1:test_length,]
x1 <- Z[(test_length+1):(jt - h),]
# I save them now, I will add them back at the end of PCA
x0_y <- x0[,"y"]
x1_y <- x1[,"y"]
Z_y <- Z_temp[,"y"]
# I remove the column of 1 and "y", the past GDP observation
x0 <- x0[, - ncol(x0)]
x1 <- x1[, - ncol(x1)]
Z_temp <- Z_temp[,- ncol(Z_temp)]
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-5)
x0 <- x0[, indexes]
x1 <- x1[, indexes]
Z_temp <- Z_temp[, indexes]
x0 <- as.matrix(cbind(cbind(x0),x0_y))
x1 <- as.matrix(cbind(cbind(x1),x1_y))
Z_temp <- as.matrix(cbind(cbind(Z_temp),Z_y))
indexes
sum(indexes)
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
Z_temp <- Z
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length+1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
x0 <- Z[1:test_length,]
x1 <- Z[(test_length+1):(jt - h),]
# ---- Preparation for PCA
# I save them now, I will add them back at the end of PCA
x0_y <- x0[,"y"]
x1_y <- x1[,"y"]
Z_y <- Z_temp[,"y"]
# I remove the column of 1 and "y", the past GDP observation
x0 <- x0[, - ncol(x0)]
x1 <- x1[, - ncol(x1)]
Z_temp <- Z_temp[,- ncol(Z_temp)]
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-5)
x0 <- x0[, indexes]
x1 <- x1[, indexes]
Z_temp <- Z_temp[, indexes]
x0 <- as.matrix(cbind(cbind(x0),x0_y))
x1 <- as.matrix(cbind(cbind(x1),x1_y))
Z_temp <- as.matrix(cbind(cbind(Z_temp),Z_y))
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-7)
sum(indexes)
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-9)
sum(indixes)
sum(indexes)
#This script....
# NOTE: this script should be run separately for one quarter and four quarter ahead forecast horizons
# by manually changing the variable 'h'.
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)
# Clear workspace
rm(list = ls())
# Set forecast horizon
h <- 4
loadsavedresults = FALSE; # TRUE If I have run the code already and I want to load results, stored in ResOOS_CQR_QR_H
# Load data and functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/To-Conformalise-or-not-to-Conformalise-in-Growth-at-Risk-Analysis/functions.R")
file_path <- "Data_NFCI_div.xls"
# Read the file and  Filter data for 1973Q1-2015Q4
data <- read_excel(file_path)
data <- data[,-c(3:10)] # Making sure to have only components of NFCI i
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time
# Set forecast settings
QQ <- seq(0.03, 0.99, by = 0.01) #We don't implement a smoothing, as in Adrian et al., but use a much finer quantile grid
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)
Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
Yh[1:(h-1)] <- NA
}
# Construct matrices of regressors
Z <- as.matrix(cbind(1, scale(X[,-1]), y))
apply(Z, 2, var)
if (loadsavedresults == FALSE) {
{
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)
# Raw quantiles
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_low_OOSCOdiv <- YQ_NaNs
YQ_high_OOSCOdiv <- YQ_NaNs
YQ_OOSCOdiv <- YQ_NaNs
YQGDPonly_high_OOSCOdiv <- YQ_NaNs
YQGDPonly_low_OOSCOdiv <- YQ_NaNs
YQGDPonly_OOSCOdiv <- YQ_NaNs
# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_OOSCOdiv <- Pit_NaNs
PitSTGDPonly_OOSCOdiv <- Pit_NaNs
}
for (jt in jtFirstOOS:(length(Time) - h)) {
YhRealized <- Yh[jt + h]
if (lubridate::month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
#------- CQR QR with NFCI components and GDP, out-of-sample
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
x0_y <- Z[1:test_length,"y"]
x1_y <- Z[(test_length+1):(jt - h),"y"]
Z_y <- Z[,"y"]
# I extract the observations I need at this time step "jt" and I scale it, preparing it for PCA
Z_temp <- scale(Z[1:jt,])
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length + 1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
x0 <- Z_temp[1:test_length,]
x1 <- Z_temp[(test_length+1):(jt - h),]
# ---- Preparation for PCA
# I remove the column of 1 and "y", the past GDP observation
x0 <- x0[, - ncol(x0)]
x1 <- x1[, - ncol(x1)]
Z_temp <- Z_temp[,- ncol(Z_temp)]
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-5)
x0 <- x0[, indexes]
x1 <- x1[, indexes]
Z_temp <- Z_temp[, indexes]
x0 <- as.matrix(cbind(cbind(x0),x0_y))
x1 <- as.matrix(cbind(cbind(x1),x1_y))
Z_temp <- as.matrix(cbind(cbind(Z_temp),Z_y))
# pca_result <- prcomp(x0, center = TRUE, scale. = TRUE)
# cumulative_variance <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
# num_components <- which(cumulative_variance >= 0.90)[1] # Capture 90% of total variance
# selected_components <- pca_result$x[, 1:num_components]
#
# x1_projected <- predict(pca_result, newdata = x1)[, 1:num_components]
# Z_temp_projected <- predict(pca_result, newdata = Z_temp)[, 1:num_components]
#
# x0 <- as.matrix(cbind(cbind(selected_components),x0_y))
# x1 <- as.matrix(cbind(cbind(x1_projected),x1_y))
# Z_temp <- as.matrix(cbind(cbind(Z_temp_projected),Z_y))
x_test <- t(as.matrix(Z_temp[jt,]))
YQ_OOSCOdiv[jt + h, ] <- qCQR_opposite(x0,y0,x1,y1,x_test,QQ)
YQGDPonly_OOSCOdiv[jt + h, ] <- qCQR_opposite(xGDPonly0,y0,xGDPonly1,y1,xGDPonly_test,QQ)
PitST_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQ_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
PitSTGDPonly_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
}
}
#This script....
# NOTE: this script should be run separately for one quarter and four quarter ahead forecast horizons
# by manually changing the variable 'h'.
library(quantreg)
library(lubridate)
library(pracma)
library(readxl)
library(sn)
library(parallel)
# Clear workspace
rm(list = ls())
# Set forecast horizon
h <- 4
loadsavedresults = FALSE; # TRUE If I have run the code already and I want to load results, stored in ResOOS_CQR_QR_H
# Load data and functions
source("C:/Users/Pietro/Desktop/Pietro/Politecnico/Tesi/To-Conformalise-or-not-to-Conformalise-in-Growth-at-Risk-Analysis/functions.R")
file_path <- "Data_NFCI_div.xls"
# Read the file and  Filter data for 1973Q1-2015Q4
data <- read_excel(file_path)
data <- data[,-c(3:10)] # Making sure to have only components of NFCI i
colnames(data)[1] <- "Time"
data$Time <- as.Date(data$Time)
data <- data[data$Time >= as.Date("1973-01-01") & data$Time <= as.Date("2015-10-01"), ]
X <- data[,-1]
Time <- data$Time
# Set forecast settings
QQ <- seq(0.03, 0.99, by = 0.01) #We don't implement a smoothing, as in Adrian et al., but use a much finer quantile grid
deltaYY <- 0.1
YY <- seq(-20, 20, by = deltaYY)
jtFirstOOS <- which(year(data$Time) == 1993 & month(data$Time) == 1)
# Construct average growth rates
y <- X$A191RL1Q225SBEA
Yh <- matrix(0, nrow=length(y), ncol=4)
Yh <- stats::filter(y, rep(1/h, h), sides=1) #If h = 1, y = Yh
if (h>1){
Yh[1:(h-1)] <- NA
}
# Construct matrices of regressors
Z <- as.matrix(cbind(1, X[,-1], y))
ZGDPonly <- cbind(1, y)
if (loadsavedresults == FALSE) {
{
len_time <- length(data$Time)
len_qq <- length(QQ)
len_yy <- length(YY)
# Raw quantiles
YQ_NaNs <- matrix(NA, len_time, len_qq)
YQ_low_OOSCOdiv <- YQ_NaNs
YQ_high_OOSCOdiv <- YQ_NaNs
YQ_OOSCOdiv <- YQ_NaNs
YQGDPonly_high_OOSCOdiv <- YQ_NaNs
YQGDPonly_low_OOSCOdiv <- YQ_NaNs
YQGDPonly_OOSCOdiv <- YQ_NaNs
# Probability integral transforms
Pit_NaNs <- rep(NA, len_time)
PitST_OOSCOdiv <- Pit_NaNs
PitSTGDPonly_OOSCOdiv <- Pit_NaNs
}
for (jt in jtFirstOOS:(length(Time) - h)) {
YhRealized <- Yh[jt + h]
if (lubridate::month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
#------- CQR QR with NFCI components and GDP, out-of-sample
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
x0_y <- Z[1:test_length,"y"]
x1_y <- Z[(test_length+1):(jt - h),"y"]
Z_y <- Z[,"y"]
# I extract the observations I need at this time step "jt" and I scale it, preparing it for PCA
Z_temp <- scale(Z[1:jt,])
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length + 1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
x0 <- Z_temp[1:test_length,]
x1 <- Z_temp[(test_length+1):(jt - h),]
# ---- Preparation for PCA
# I remove the column of 1 and "y", the past GDP observation
x0 <- x0[, - ncol(x0)]
x1 <- x1[, - ncol(x1)]
Z_temp <- Z_temp[,- ncol(Z_temp)]
# I want to remove columns (i.e. NFCI components) that do not change in I1, the training set
indexes <- apply(x0, 2, function(x) var(x) > 1e-5)
x0 <- x0[, indexes]
x1 <- x1[, indexes]
Z_temp <- Z_temp[, indexes]
x0 <- as.matrix(cbind(cbind(x0),x0_y))
x1 <- as.matrix(cbind(cbind(x1),x1_y))
Z_temp <- as.matrix(cbind(cbind(Z_temp),Z_y))
# pca_result <- prcomp(x0, center = TRUE, scale. = TRUE)
# cumulative_variance <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
# num_components <- which(cumulative_variance >= 0.90)[1] # Capture 90% of total variance
# selected_components <- pca_result$x[, 1:num_components]
#
# x1_projected <- predict(pca_result, newdata = x1)[, 1:num_components]
# Z_temp_projected <- predict(pca_result, newdata = Z_temp)[, 1:num_components]
#
# x0 <- as.matrix(cbind(cbind(selected_components),x0_y))
# x1 <- as.matrix(cbind(cbind(x1_projected),x1_y))
# Z_temp <- as.matrix(cbind(cbind(Z_temp_projected),Z_y))
x_test <- t(as.matrix(Z_temp[jt,]))
YQ_OOSCOdiv[jt + h, ] <- qCQR_opposite(x0,y0,x1,y1,x_test,QQ)
YQGDPonly_OOSCOdiv[jt + h, ] <- qCQR_opposite(xGDPonly0,y0,xGDPonly1,y1,xGDPonly_test,QQ)
PitST_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQ_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
PitSTGDPonly_OOSCOdiv[jt + h] <- pst(YhRealized, QQ, YQGDPonly_OOSCOdiv[jt + h, ]) # is the probability to observe a value < of YhRealized in this distribution
}
}
YhRealized <- Yh[jt + h]
if (lubridate::month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
x0_y <- Z[1:test_length,"y"]
x1_y <- Z[(test_length+1):(jt - h),"y"]
Z_y <- Z[,"y"]
# I extract the observations I need at this time step "jt" and I scale it, preparing it for PCA
Z_temp <- scale(Z[1:jt,])
View(Z)
View(Z_temp)
# I extract the observations I need at this time step "jt" and I remove the columns that do not change
Z_temp <- Z[1:jt, apply(Z[1:jt,], 2, function(x) var(x) > 1e-5) ]
YhRealized <- Yh[jt + h]
if (lubridate::month(Time[jt]) == 1) {
cat(sprintf("Now computing the real-time predictive densities in %d", year(Time[jt])), "\n")
}
#------- CQR QR with NFCI components and GDP, out-of-sample
# Split creating I1 and I2
full_length <- length(Yh[(h + 1):jt])
test_length = full_length*50/100
xGDPonly0 <- ZGDPonly[1:test_length,]
xGDPonly1 <- ZGDPonly[(test_length + 1):(jt - h),]
xGDPonly_test <- t(as.matrix(ZGDPonly[jt,]))
y0 <- Yh[(h+1):(h+test_length)]
y1 <- Yh[(h+1+test_length):jt]
# I extract the "y" value (previous GDP value), to be added after PCA
x0_y <- Z[1:test_length,"y"]
x1_y <- Z[(test_length+1):(jt - h),"y"]
Z_y <- Z[,"y"]
# I extract the observations I need at this time step "jt" and I remove the columns that do not change
Z_temp <- Z[1:jt, apply(Z[1:jt,], 2, function(x) var(x) > 1e-5) ]
x0 <- Z_temp[1:test_length,]
x1 <- Z_temp[(test_length+1):(jt - h),]
pca_result <- prcomp(x0, center = TRUE, scale. = TRUE)
cumulative_variance <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
View(x0)
